{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from dice_loss import *\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import confusion_matrix,precision_score,recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ND_Crossentropy import CrossentropyND, TopKLoss, WeightedCrossEntropyLoss\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch import einsum\n",
    "import numpy as np\n",
    "\n",
    "def softmax_helper(x):\n",
    "    # copy from: https://github.com/MIC-DKFZ/nnUNet/blob/master/nnunet/utilities/nd_softmax.py\n",
    "    rpt = [1 for _ in range(len(x.size()))]\n",
    "    rpt[1] = x.size(1)\n",
    "    x_max = x.max(1, keepdim=True)[0].repeat(*rpt)\n",
    "    e_x = torch.exp(x - x_max)\n",
    "    return e_x / e_x.sum(1, keepdim=True).repeat(*rpt)\n",
    "\n",
    "def sum_tensor(inp, axes, keepdim=False):\n",
    "    # copy from: https://github.com/MIC-DKFZ/nnUNet/blob/master/nnunet/utilities/tensor_utilities.py\n",
    "    axes = np.unique(axes).astype(int)\n",
    "    if keepdim:\n",
    "        for ax in axes:\n",
    "            inp = inp.sum(int(ax), keepdim=True)\n",
    "    else:\n",
    "        for ax in sorted(axes, reverse=True):\n",
    "            inp = inp.sum(int(ax))\n",
    "    return inp\n",
    "\n",
    "def get_tp_fp_fn(net_output, gt, axes=None, mask=None, square=False):\n",
    "    \"\"\"\n",
    "    net_output must be (b, c, x, y(, z)))\n",
    "    gt must be a label map (shape (b, 1, x, y(, z)) OR shape (b, x, y(, z))) or one hot encoding (b, c, x, y(, z))\n",
    "    if mask is provided it must have shape (b, 1, x, y(, z)))\n",
    "    :param net_output:\n",
    "    :param gt:\n",
    "    :param axes:\n",
    "    :param mask: mask must be 1 for valid pixels and 0 for invalid pixels\n",
    "    :param square: if True then fp, tp and fn will be squared before summation\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if axes is None:\n",
    "        axes = tuple(range(2, len(net_output.size())))\n",
    "\n",
    "    shp_x = net_output.shape\n",
    "    shp_y = gt.shape\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if len(shp_x) != len(shp_y):\n",
    "            gt = gt.view((shp_y[0], 1, *shp_y[1:]))\n",
    "\n",
    "        if all([i == j for i, j in zip(net_output.shape, gt.shape)]):\n",
    "            # if this is the case then gt is probably already a one hot encoding\n",
    "            y_onehot = gt\n",
    "        else:\n",
    "            gt = gt.long()\n",
    "            y_onehot = torch.zeros(shp_x)\n",
    "            if net_output.device.type == \"cuda\":\n",
    "                y_onehot = y_onehot.cuda(net_output.device.index)\n",
    "            y_onehot.scatter_(1, gt, 1)\n",
    "    tp = net_output * y_onehot\n",
    "    fp = net_output * (1 - y_onehot)\n",
    "    fn = (1 - net_output) * y_onehot\n",
    "\n",
    "    if mask is not None:\n",
    "        tp = torch.stack(tuple(x_i * mask[:, 0] for x_i in torch.unbind(tp, dim=1)), dim=1)\n",
    "        fp = torch.stack(tuple(x_i * mask[:, 0] for x_i in torch.unbind(fp, dim=1)), dim=1)\n",
    "        fn = torch.stack(tuple(x_i * mask[:, 0] for x_i in torch.unbind(fn, dim=1)), dim=1)\n",
    "\n",
    "    if square:\n",
    "        tp = tp ** 2\n",
    "        fp = fp ** 2\n",
    "        fn = fn ** 2\n",
    "\n",
    "    tp = sum_tensor(tp, axes, keepdim=False)\n",
    "    fp = sum_tensor(fp, axes, keepdim=False)\n",
    "    fn = sum_tensor(fn, axes, keepdim=False)\n",
    "\n",
    "    return tp, fp, fn\n",
    "    \n",
    "class IoULoss(nn.Module):\n",
    "    def __init__(self, apply_nonlin=None, batch_dice=False, do_bg=True, smooth=1.,\n",
    "                 square=False):\n",
    "        \"\"\"\n",
    "        paper: https://link.springer.com/chapter/10.1007/978-3-319-50835-1_22\n",
    "        \n",
    "        \"\"\"\n",
    "        super(IoULoss, self).__init__()\n",
    "\n",
    "        self.square = square\n",
    "        self.do_bg = do_bg\n",
    "        self.batch_dice = batch_dice\n",
    "        self.apply_nonlin = apply_nonlin\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, pred, true, loss_mask=None):\n",
    "        batch=pred.size(0)\n",
    "        iou=0\n",
    "        for i in range(batch):\n",
    "            x,y=pred[i],true[i]\n",
    "            shp_x = x.shape\n",
    "\n",
    "            if self.batch_dice:\n",
    "                axes = [0] + list(range(2, len(shp_x)))\n",
    "            else:\n",
    "                axes = list(range(2, len(shp_x)))\n",
    "\n",
    "            if self.apply_nonlin is not None:\n",
    "                x = self.apply_nonlin(x)\n",
    "\n",
    "            tp, fp, fn = get_tp_fp_fn(x, y, axes, loss_mask, self.square)\n",
    "            tp=tp.sum(dim=0)\n",
    "            fp=fp.sum(dim=0)\n",
    "            fn=fn.sum(dim=0)\n",
    "\n",
    "\n",
    "            batch_iou = (tp + self.smooth) / (tp + fp + fn + self.smooth)\n",
    "             \n",
    "            \"\"\"if not self.do_bg:\n",
    "                if self.batch_dice:\n",
    "                    batch_iou=batch_iou[1:]\n",
    "                else:\n",
    "                    batch_iou = batch_iou[:, 1:]\"\"\"\n",
    "        iou = batch_iou.mean()/batch\n",
    "\n",
    "        return 1-iou,tp, fp, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=torch.randn(1,100,6)\n",
    "pred=F.softmax(pred,dim=2)\n",
    "true=torch.randint(0,6,(1,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "true=torch.argmax(pred,dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=F.one_hot(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1020, 0.1190, 0.0961, 0.1094, 0.0967, 0.1164])\n"
     ]
    }
   ],
   "source": [
    "iou=IoULoss()\n",
    "iouVal,tp,fp,fn=iou(pred,true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8711)"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iouVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9.4910, 16.9072, 16.2748, 13.9113, 15.8984,  9.7754])"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(true[0],torch.argmax(pred,dim=2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05555556, 0.25      , 0.2       , 0.27777778, 0.2       ,\n",
       "       0.05555556])"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(true[0],torch.argmax(pred,dim=2)[0],average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp=np.diagonal(cm)\n",
    "fp=-(1-1/precision_score(true[0],torch.argmax(pred,dim=2)[0],average=None))*tp\n",
    "fn=-(1-1/recall_score(true[0],torch.argmax(pred,dim=2)[0],average=None))*tp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10., 17., 16., 13., 16., 11.])"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3, 3, 2, 1, 1],\n",
       "       [7, 4, 5, 2, 0, 3],\n",
       "       [1, 4, 3, 3, 4, 4],\n",
       "       [2, 2, 2, 5, 4, 3],\n",
       "       [4, 2, 0, 4, 3, 6],\n",
       "       [3, 1, 2, 2, 3, 1]])"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((tp)/(tp+fp+fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(true[0],torch.argmax(pred,dim=2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 2, 2, 1, 4, 1],\n",
       "       [0, 6, 1, 2, 4, 8],\n",
       "       [1, 1, 1, 3, 3, 4],\n",
       "       [3, 1, 3, 6, 4, 1],\n",
       "       [2, 4, 0, 4, 3, 8],\n",
       "       [3, 3, 2, 3, 2, 1]])"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c4e8fb3c1082bb46ec33d3c97266bb7042a653e1394115648c2c3a5c1250857d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('dl_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
